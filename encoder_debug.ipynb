{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import torch\n",
    "import torch_geometric.utils\n",
    "from e3nn import o3\n",
    "from e3nn import nn as enn\n",
    "from e3nn.math import soft_one_hot_linspace\n",
    "from e3nn.nn import Gate\n",
    "from e3nn.util.jit import compile_mode\n",
    "\n",
    "import rem.e3nn_utils as e3nn_utils\n",
    "import rem.pooling as pooling\n",
    "\n",
    "from datasets import DragMeshDataset\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    irreps_node_input,\n",
    "    irreps_node_output,\n",
    "    max_radius,\n",
    "    mul=50,\n",
    "    layers=3,\n",
    "    lmax=2,\n",
    "    pool_nodes=True,\n",
    "  ) -> None:\n",
    "    super().__init__()\n",
    "\n",
    "    self.lmax = lmax\n",
    "    self.max_radius = max_radius\n",
    "    self.number_of_basis = 10\n",
    "    self.pool_nodes = pool_nodes\n",
    "\n",
    "    irreps_node_hiddens = list()\n",
    "    irreps_edge_hiddens = list()\n",
    "    for layer_lmax in lmax[:-1]:\n",
    "      irreps_node_hiddens.append(o3.Irreps(\n",
    "        #[(mul * 2 * l + 1, (l, 1)) for l in range(layer_lmax + 1)]\n",
    "        [(mul, (l, p)) for l in range(layer_lmax + 1) for p in [-1, 1]]\n",
    "      ))\n",
    "      irreps_edge_hiddens.append(o3.Irreps.spherical_harmonics(layer_lmax))\n",
    "\n",
    "\n",
    "    self.irreps_node_seq = [irreps_node_input] + irreps_node_hiddens + [irreps_node_output]\n",
    "    irreps_edge_seq = irreps_edge_hiddens + [o3.Irreps.spherical_harmonics(lmax[-1])]\n",
    "    self.mp = MessagePassing(\n",
    "      irreps_node_sequence=self.irreps_node_seq,\n",
    "      irreps_edge_attrs=irreps_edge_seq,\n",
    "      fc_neurons=[self.number_of_basis, 100],\n",
    "      max_radius=max_radius,\n",
    "      lmax=self.lmax\n",
    "    )\n",
    "    self.irreps_node_input = self.mp.irreps_node_input\n",
    "    self.irreps_node_output = self.mp.irreps_node_output\n",
    "\n",
    "  def forward(self, data: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
    "    batch, node_outputs = self.mp(data)\n",
    "\n",
    "    if self.pool_nodes:\n",
    "      return torch_geometric.utils.scatter(node_outputs, batch, dim=0, reduce='mean')\n",
    "    else:\n",
    "      return node_outputs\n",
    "\n",
    "class MessagePassing(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self,\n",
    "    irreps_node_sequence,\n",
    "    irreps_edge_attrs,\n",
    "    fc_neurons,\n",
    "    max_radius,\n",
    "    lmax,\n",
    "  ) -> None:\n",
    "    super().__init__()\n",
    "    self.lmax = lmax\n",
    "    self.max_radius = max_radius\n",
    "    self.number_of_basis = 10\n",
    "\n",
    "    irreps_node_sequence = [o3.Irreps(irreps) for irreps in irreps_node_sequence]\n",
    "    self.irreps_edge_attrs = [o3.Irreps(irreps) for irreps in irreps_edge_attrs]\n",
    "\n",
    "    act = {\n",
    "      1: torch.nn.functional.silu,\n",
    "      -1: torch.tanh,\n",
    "    }\n",
    "    act_gates = {\n",
    "      1: torch.sigmoid,\n",
    "      -1: torch.tanh,\n",
    "    }\n",
    "\n",
    "    self.layers = torch.nn.ModuleList()\n",
    "\n",
    "    self.irreps_node_sequence = [irreps_node_sequence[0]]\n",
    "    irreps_node = irreps_node_sequence[0]\n",
    "\n",
    "    for li, (irreps_node_hidden, irreps_edge_attr) in enumerate(zip(irreps_node_sequence[1:-1], self.irreps_edge_attrs[:-1])):\n",
    "      irreps_scalars = o3.Irreps(\n",
    "        [\n",
    "          (mul, ir)\n",
    "          for mul, ir in irreps_node_hidden\n",
    "          if ir.l == 0\n",
    "          and e3nn_utils.tp_path_exists(\n",
    "            irreps_node, irreps_edge_attr, ir\n",
    "          )\n",
    "        ]\n",
    "      ).simplify()\n",
    "      irreps_gated = o3.Irreps(\n",
    "        [\n",
    "          (mul, ir)\n",
    "          for mul, ir in irreps_node_hidden\n",
    "          if ir.l > 0\n",
    "          and e3nn_utils.tp_path_exists(\n",
    "            irreps_node, irreps_edge_attr, ir\n",
    "          )\n",
    "        ]\n",
    "      )\n",
    "      if irreps_gated.dim > 0:\n",
    "        if e3nn_utils.tp_path_exists(irreps_node, irreps_edge_attr, \"0e\"):\n",
    "          ir = \"0e\"\n",
    "        elif e3nn_utils.tp_path_exists(\n",
    "          irreps_node, irreps_edge_attr, \"0o\"\n",
    "        ):\n",
    "          ir = \"0o\"\n",
    "        else:\n",
    "          raise ValueError(\n",
    "            f\"irreps_node={irreps_node} times irreps_edge_attr={self.irreps_edge_attr} is unable to produce gates \"\n",
    "            f\"needed for irreps_gated={irreps_gated}\"\n",
    "          )\n",
    "      else:\n",
    "        ir = None\n",
    "      irreps_gates = o3.Irreps([(mul, ir) for mul, _ in irreps_gated]).simplify()\n",
    "\n",
    "      gate = Gate(\n",
    "        irreps_scalars,\n",
    "        [act[ir.p] for _, ir in irreps_scalars],  # scalar\n",
    "        irreps_gates,\n",
    "        [act_gates[ir.p] for _, ir in irreps_gates],  # gates (scalars)\n",
    "        irreps_gated,  # gated tensors\n",
    "      )\n",
    "      conv = GraphConvolution(\n",
    "        irreps_node,\n",
    "        irreps_edge_attr,\n",
    "        gate.irreps_in,\n",
    "        fc_neurons,\n",
    "      )\n",
    "      #if li == 1:\n",
    "      #  pool = pooling.VoxelPooling(gate.irreps_out, self.lmax, [0.5, 0.5, 0.5])#, start=[-2, -2, -2],end=[2, 2, 2])\n",
    "      #else:\n",
    "      #  pool = pooling.VoxelPooling(gate.irreps_out, self.lmax, [0.1, 0.1, 0.5])#, start=[-2, -2, -2],end=[2, 2, 2])\n",
    "      #pool = pooling.EdgePooling(gate.irreps_out, self.lmax)\n",
    "      pool = pooling.TopKPooling(gate.irreps_out, self.lmax)\n",
    "      #pool = None\n",
    "      self.layers.append(e3nn_utils.GraphConvBlock(conv, gate))\n",
    "      irreps_node = gate.irreps_out\n",
    "      self.irreps_node_sequence.append(irreps_node)\n",
    "\n",
    "    irreps_node_output = irreps_node_sequence[-1]\n",
    "    self.layers.append(\n",
    "      e3nn_utils.GraphConvBlock(\n",
    "        GraphConvolution(\n",
    "          irreps_node,\n",
    "          self.irreps_edge_attrs[-1],\n",
    "          irreps_node_output,\n",
    "          fc_neurons,\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    \n",
    "\n",
    "    self.irreps_node_sequence.append(irreps_node_output)\n",
    "\n",
    "    self.irreps_node_input = self.irreps_node_sequence[0]\n",
    "    self.irreps_node_output = self.irreps_node_sequence[-1]\n",
    "\n",
    "  def forward(self, data) -> torch.Tensor:\n",
    "    for i, lay in enumerate(self.layers):\n",
    "      # Edge attributes\n",
    "      edge_sh = o3.spherical_harmonics(\n",
    "        range(self.lmax[i] + 1), data.edge_vec, True, normalization=\"component\"\n",
    "      )\n",
    "      data.edge_attr_sh = edge_sh\n",
    "\n",
    "      # Edge length embedding\n",
    "      edge_length = data.edge_vec.norm(dim=1)\n",
    "      data.edge_scalars = soft_one_hot_linspace(\n",
    "        edge_length,\n",
    "        0.0,\n",
    "        self.max_radius,\n",
    "        self.number_of_basis,\n",
    "        basis=\"smooth_finite\",  # the smooth_finite basis with cutoff = True goes to zero at max_radius\n",
    "        cutoff=True,  # no need for an additional smooth cutoff\n",
    "      ).mul(self.number_of_basis**0.5)\n",
    "\n",
    "      # Forward\n",
    "      data = lay(data)\n",
    "    \n",
    "    # data.x = self.final_act(data.x)\n",
    "\n",
    "    return data.batch, data.x\n",
    "\n",
    "@compile_mode(\"script\")\n",
    "class GraphConvolution(torch.nn.Module):\n",
    "  def __init__(\n",
    "    self, irreps_node_input, irreps_edge_attr, irreps_node_output, fc_neurons\n",
    "  ) -> None:\n",
    "    super().__init__()\n",
    "    self.irreps_node_input = o3.Irreps(irreps_node_input)\n",
    "    self.irreps_edge_attr = o3.Irreps(irreps_edge_attr)\n",
    "    self.irreps_node_output = o3.Irreps(irreps_node_output)\n",
    "    self.sc = o3.Linear(self.irreps_node_input, self.irreps_node_output)\n",
    "    # self.lin1 = o3.FullyConnectedTensorProduct(self.irreps_node_input, self.irreps_node_attr, self.irreps_node_input)\n",
    "\n",
    "    irreps_mid = []\n",
    "    instructions = []\n",
    "    for i, (mul, ir_in) in enumerate(self.irreps_node_input):\n",
    "      for j, (_, ir_edge) in enumerate(self.irreps_edge_attr):\n",
    "        for ir_out in ir_in * ir_edge:\n",
    "          if ir_out in self.irreps_node_output or ir_out == o3.Irrep(0, 1):\n",
    "            k = len(irreps_mid)\n",
    "            irreps_mid.append((mul, ir_out))\n",
    "            instructions.append((i, j, k, \"uvu\", True))\n",
    "    irreps_mid = o3.Irreps(irreps_mid)\n",
    "    irreps_mid, p, _ = irreps_mid.sort()\n",
    "\n",
    "    assert irreps_mid.dim > 0, (\n",
    "      f\"irreps_node_input={self.irreps_node_input} time irreps_edge_attr={self.irreps_edge_attr} produces nothing \"\n",
    "      f\"in irreps_node_output={self.irreps_node_output}\"\n",
    "    )\n",
    "    instructions = [(i_1, i_2, p[i_out], mode, train) for i_1, i_2, i_out, mode, train in instructions]\n",
    "\n",
    "    tp = o3.TensorProduct(\n",
    "      self.irreps_node_input,\n",
    "      self.irreps_edge_attr,\n",
    "      irreps_mid,\n",
    "      instructions,\n",
    "      internal_weights=False,\n",
    "      shared_weights=False,\n",
    "    )\n",
    "    self.fc = enn.FullyConnectedNet(fc_neurons + [tp.weight_numel], torch.nn.functional.silu)\n",
    "    self.tp = tp\n",
    "\n",
    "    self.lin = o3.Linear(irreps_mid, self.irreps_node_output)\n",
    "    # self.lin2 = o3.FullyConnectedTensorProduct(...)\n",
    "\n",
    "    # inspired by https://arxiv.org/pdf/2002.10444.pdf\n",
    "    self.alpha = o3.Linear(irreps_mid, \"0e\")\n",
    "    # with torch.no_grad():\n",
    "    #   self.alpha.weight.zero_()\n",
    "\n",
    "  def forward(self, data) -> torch.Tensor:\n",
    "    weight = self.fc(data.edge_scalars)\n",
    "\n",
    "    node_self_connection =  self.sc(data.x)\n",
    "    # print(f\"Node self connection: {node_self_connection.shape}\")\n",
    "    # print(node_self_connection)\n",
    "    edge_features = self.tp(data.x[data.edge_index[0]], data.edge_attr_sh, weight)\n",
    "    # print(f\"Edge features: {edge_features.shape}\")\n",
    "    # print(edge_features)\n",
    "    node_features = torch_geometric.utils.scatter(edge_features, data.edge_index[1], dim=0, dim_size=data.x.shape[0], reduce='mean')\n",
    "    # print(f\"Node features: {node_features.shape}\")\n",
    "    # print(node_features)\n",
    "\n",
    "    alpha = self.alpha(node_features)\n",
    "    # print(f\"Alpha: {alpha.shape}\")\n",
    "    # print(alpha)\n",
    "    node_conv_out = self.lin(node_features)\n",
    "    # print(f\"Node conv out: {node_conv_out.shape}\")\n",
    "    # print(node_conv_out)\n",
    "\n",
    "    m = self.sc.output_mask\n",
    "    alpha = (1 - m) + alpha * m\n",
    "    return node_self_connection + alpha * node_conv_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x0e\n",
      "4x0e+1x1o\n",
      "[5x0e, 50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e, 50x0o+50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e, 4x0e+1x1o]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GNN(\n",
       "  (mp): MessagePassing(\n",
       "    (layers): ModuleList(\n",
       "      (0): GraphConvBlock(\n",
       "        (gconv): GraphConvolution(\n",
       "          (sc): Linear(5x0e -> 300x0e+50x1o+50x2e+50x3o+50x4e+50x5o | 1500 weights)\n",
       "          (fc): FullyConnectedNet[10, 100, 30]\n",
       "          (tp): TensorProduct(5x0e x 1x0e+1x1o+1x2e+1x3o+1x4e+1x5o -> 5x0e+5x1o+5x2e+5x3o+5x4e+5x5o | 30 paths | 30 weights)\n",
       "          (lin): Linear(5x0e+5x1o+5x2e+5x3o+5x4e+5x5o -> 300x0e+50x1o+50x2e+50x3o+50x4e+50x5o | 2750 weights)\n",
       "          (alpha): Linear(5x0e+5x1o+5x2e+5x3o+5x4e+5x5o -> 1x0e | 5 weights)\n",
       "        )\n",
       "        (act): Gate (300x0e+50x1o+50x2e+50x3o+50x4e+50x5o -> 50x0e+50x1o+50x2e+50x3o+50x4e+50x5o)\n",
       "      )\n",
       "      (1): GraphConvBlock(\n",
       "        (gconv): GraphConvolution(\n",
       "          (sc): Linear(50x0e+50x1o+50x2e+50x3o+50x4e+50x5o -> 550x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e | 40000 weights)\n",
       "          (fc): FullyConnectedNet[10, 100, 5550]\n",
       "          (tp): TensorProduct(50x0e+50x1o+50x2e+50x3o+50x4e+50x5o x 1x0e+1x1o+1x2e+1x3o+1x4e+1x5o -> 300x0e+500x1o+250x1e+400x2o+650x2e+700x3o+500x3e+500x4o+700x4e+600x5o+450x5e | 5550 paths | 5550 weights)\n",
       "          (lin): Linear(50x0e+50x0e+50x0e+50x0e+50x0e+50x0e+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1e+50x1e+50x1e+50x1e+50x1e+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e -> 550x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e | 427500 weights)\n",
       "          (alpha): Linear(50x0e+50x0e+50x0e+50x0e+50x0e+50x0e+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1e+50x1e+50x1e+50x1e+50x1e+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2o+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x2e+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3o+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x3e+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4o+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x4e+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5o+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e+50x5e -> 1x0e | 300 weights)\n",
       "        )\n",
       "        (act): Gate (550x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e -> 50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e)\n",
       "      )\n",
       "      (2): GraphConvBlock(\n",
       "        (gconv): GraphConvolution(\n",
       "          (sc): Linear(50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e -> 4x0e+1x1o | 250 weights)\n",
       "          (fc): FullyConnectedNet[10, 100, 1050]\n",
       "          (tp): TensorProduct(50x0e+50x1o+50x1e+50x2o+50x2e+50x3o+50x3e+50x4o+50x4e+50x5o+50x5e x 1x0e+1x1o+1x2e+1x3o+1x4e+1x5o -> 300x0e+750x1o | 1050 paths | 1050 weights)\n",
       "          (lin): Linear(50x0e+50x0e+50x0e+50x0e+50x0e+50x0e+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o -> 4x0e+1x1o | 1950 weights)\n",
       "          (alpha): Linear(50x0e+50x0e+50x0e+50x0e+50x0e+50x0e+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o+50x1o -> 1x0e | 300 weights)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_act): SO3Activation (5 -> 0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmax = 5\n",
    "irreps_in = o3.Irreps(\"5x0e\")\n",
    "# irreps_out = o3.Irreps(\"16x0o+16x0e+16x1o+16x1e+16x2o+16x2e+16x3o+16x3e+16x4o+16x4e\")\n",
    "irreps_out = o3.Irreps(\"4x0e + 1x1o\")\n",
    "encoder = GNN(\n",
    "    irreps_node_input=irreps_in,\n",
    "    irreps_node_output=irreps_out,\n",
    "    max_radius=1.7,\n",
    "    mul=50,\n",
    "    pool_nodes=True,\n",
    "    lmax=[lmax, lmax, lmax],\n",
    ")\n",
    "\n",
    "print(encoder.irreps_node_input)\n",
    "print(encoder.irreps_node_output)\n",
    "print(encoder.irreps_node_seq)\n",
    "\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neelsortur/Documents/codestuff/sat-modeling/satellite-edcm/datasets.py:54: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(utils.to_absolute_path(attr_file), delim_whitespace=True, header=None)\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "ds = DragMeshDataset(\"data/cube50k.dat\", \"STLs/Cube_38_1m.stl\", return_features_separately=False)\n",
    "dl = iter(DataLoader(ds, batch_size=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[38, 5], edge_index=[2, 108], pos=[38, 3], edge_vec=[108, 3], orientation=[1, 2], batch=[38], ptr=[2])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279],\n",
      "        [0.4587, 0.5424, 0.5712, 0.2145, 0.8279]])\n",
      "tensor([[-5.0000e-01,  5.0000e-01,  0.0000e+00],\n",
      "        [-5.0000e-01,  5.0000e-01, -5.0000e-01],\n",
      "        [-5.0000e-01,  0.0000e+00, -5.0000e-01],\n",
      "        [-5.0000e-01,  1.4624e-01, -1.4639e-01],\n",
      "        [-5.0000e-01,  0.0000e+00,  5.0000e-01],\n",
      "        [-5.0000e-01, -1.5055e-01,  1.4442e-01],\n",
      "        [-5.0000e-01, -5.0000e-01,  0.0000e+00],\n",
      "        [-5.0000e-01, -5.0000e-01,  5.0000e-01],\n",
      "        [-5.0000e-01,  5.0000e-01,  5.0000e-01],\n",
      "        [-5.0000e-01, -9.8562e-04, -7.4565e-05],\n",
      "        [-5.0000e-01, -5.0000e-01, -5.0000e-01],\n",
      "        [ 5.0000e-01,  5.0000e-01,  0.0000e+00],\n",
      "        [ 5.0000e-01,  1.4624e-01, -1.4639e-01],\n",
      "        [ 5.0000e-01,  0.0000e+00, -5.0000e-01],\n",
      "        [ 5.0000e-01,  5.0000e-01, -5.0000e-01],\n",
      "        [ 5.0000e-01,  0.0000e+00,  5.0000e-01],\n",
      "        [ 5.0000e-01, -5.0000e-01,  5.0000e-01],\n",
      "        [ 5.0000e-01, -5.0000e-01,  0.0000e+00],\n",
      "        [ 5.0000e-01, -1.5055e-01,  1.4442e-01],\n",
      "        [ 5.0000e-01,  5.0000e-01,  5.0000e-01],\n",
      "        [ 5.0000e-01, -9.8562e-04, -7.4565e-05],\n",
      "        [ 5.0000e-01, -5.0000e-01, -5.0000e-01],\n",
      "        [ 0.0000e+00, -5.0000e-01,  5.0000e-01],\n",
      "        [-1.4639e-01, -5.0000e-01,  1.4624e-01],\n",
      "        [ 1.4442e-01, -5.0000e-01, -1.5055e-01],\n",
      "        [ 0.0000e+00, -5.0000e-01, -5.0000e-01],\n",
      "        [-7.4625e-05, -5.0000e-01, -9.8562e-04],\n",
      "        [ 0.0000e+00,  5.0000e-01,  5.0000e-01],\n",
      "        [-1.4639e-01,  5.0000e-01,  1.4624e-01],\n",
      "        [ 0.0000e+00,  5.0000e-01, -5.0000e-01],\n",
      "        [ 1.4442e-01,  5.0000e-01, -1.5055e-01],\n",
      "        [-7.4625e-05,  5.0000e-01, -9.8562e-04],\n",
      "        [ 1.4624e-01, -1.4639e-01, -5.0000e-01],\n",
      "        [-1.5055e-01,  1.4442e-01, -5.0000e-01],\n",
      "        [-9.8562e-04, -7.4565e-05, -5.0000e-01],\n",
      "        [ 1.4624e-01, -1.4639e-01,  5.0000e-01],\n",
      "        [-1.5055e-01,  1.4442e-01,  5.0000e-01],\n",
      "        [-9.8562e-04, -7.4565e-05,  5.0000e-01]])\n"
     ]
    }
   ],
   "source": [
    "samp, y = next(dl)\n",
    "samp_copy = samp.clone()\n",
    "samp_copy2 = samp.clone()\n",
    "samp.orientation = torch.tensor([[0.0, 0.0]])\n",
    "print(samp)\n",
    "print(samp.orientation)\n",
    "print(samp.x)\n",
    "print(samp.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "tensor([[ 0.0529, -0.0796, -0.4811, -0.1557, -0.0017, -0.0722, -0.0789]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ret = encoder(samp)\n",
    "print(ret.shape)\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "tensor([[ 0.0529, -0.0796, -0.4811, -0.1557, -0.0017, -0.0722, -0.0789]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "samp_copy.pos = samp_copy.pos @ o3.rand_matrix()\n",
    "ret_copy = encoder(samp_copy)\n",
    "print(ret_copy.shape)\n",
    "print(ret_copy)\n",
    "# assert all close to ret\n",
    "assert torch.allclose(ret, ret_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7])\n",
      "tensor([[ 0.0529, -0.0796, -0.4811, -0.1557, -0.0017, -0.0722, -0.0789]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "noise = torch.randn_like(samp_copy2.pos) * 1.5  # small random noise shouldn't be equivariant\n",
    "samp_copy2.pos += noise\n",
    "ret_copy2 = encoder(samp_copy2)\n",
    "print(ret_copy2.shape)\n",
    "print(ret_copy2)\n",
    "\n",
    "assert torch.allclose(ret_copy2, ret, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original orientation tensor([[ 5.6706, -0.7876]])\n",
      "New orientation tensor([[-1.1105,  0.7781]])\n",
      "Equivariance Test: Passed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp, y = next(dl)\n",
    "samp_copy = samp.clone()\n",
    "from e3nn.o3 import rand_matrix\n",
    "\n",
    "def spherical_to_cartesian(alpha, beta):\n",
    "    \"\"\"\n",
    "    Convert spherical angles (alpha, beta) to cartesian coordinates.\n",
    "    alpha: azimuthal angle, beta: polar angle\n",
    "    \"\"\"\n",
    "    x = torch.cos(beta) * torch.cos(alpha)\n",
    "    y = torch.cos(beta) * torch.sin(alpha)\n",
    "    z = torch.sin(beta)\n",
    "    return torch.stack([x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "def rotate_orientation(orientation, R):\n",
    "    \"\"\"\n",
    "    Rotate 2D orientation (alpha, beta) values using a rotation matrix.\n",
    "    Orientation is converted to Cartesian, rotated, and then converted back.\n",
    "    \"\"\"\n",
    "    # Convert spherical angles (alpha, beta) to Cartesian coordinates\n",
    "    cartesian = spherical_to_cartesian(orientation[:, 0], orientation[:, 1])\n",
    "\n",
    "    # Apply rotation\n",
    "    rotated_cartesian = torch.einsum('ij,nj->ni', R, cartesian)\n",
    "\n",
    "    # Convert back to spherical coordinates\n",
    "    rho = rotated_cartesian.norm(dim=-1)\n",
    "    beta = torch.asin(rotated_cartesian[:, 2] / rho)\n",
    "    alpha = torch.atan2(rotated_cartesian[:, 1], rotated_cartesian[:, 0])\n",
    "    return torch.stack([alpha, beta], dim=-1)\n",
    "\n",
    "\n",
    "def test_encoder_equivariance(encoder, data):\n",
    "    \"\"\"\n",
    "    Test the equivariance of rem.encoder with respect to SO(3) rotations.\n",
    "\n",
    "    Parameters:\n",
    "        rem: REM\n",
    "            The REM model with the encoder to test.\n",
    "        data: torch_geometric.data.Data\n",
    "            Input graph data with `data.orientation` as (alpha, beta).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if invariant, False otherwise.\n",
    "    \"\"\"\n",
    "    # Generate a random SO(3) rotation matrix\n",
    "    R = rand_matrix()\n",
    "\n",
    "    # Rotate orientation\n",
    "    original_orientation = data.orientation.clone()\n",
    "    print(\"Original orientation\", original_orientation)\n",
    "    rotated_orientation = rotate_orientation(original_orientation, R)\n",
    "    print(\"New orientation\", rotated_orientation)\n",
    "\n",
    "    if hasattr(data, 'pos'):\n",
    "        data.pos = torch.einsum('ij,nj->ni', R, data.pos)\n",
    "        data.pos[:, 1] += 0.5\n",
    "\n",
    "    # Clone data and apply rotated orientation\n",
    "    data_rotated = data.clone()\n",
    "    data_rotated.orientation = rotated_orientation\n",
    "\n",
    "    # Forward pass on original and rotated data\n",
    "    encoder.eval()  # Ensure evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output_original = encoder(data)\n",
    "        # print(\"Output original\", output_original)\n",
    "        output_rotated = encoder(data_rotated)\n",
    "        # print(\"Output rotated\", output_rotated)\n",
    "\n",
    "    # Check invariance: the outputs should be identical\n",
    "    is_invariant = torch.allclose(output_original, output_rotated, atol=1e-6)\n",
    "\n",
    "    print(f\"Equivariance Test: {'Passed' if is_invariant else 'Failed'}\")\n",
    "    return is_invariant\n",
    "\n",
    "test_encoder_equivariance(encoder, samp_copy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satsims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
