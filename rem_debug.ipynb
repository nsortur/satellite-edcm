{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DragMeshDataset\n",
    "from torch_geometric.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neelsortur/Documents/codestuff/sat-modeling/satellite-edcm/datasets.py:54: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(utils.to_absolute_path(attr_file), delim_whitespace=True, header=None)\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# GRACE_A_tpmc\n",
    "ds = DragMeshDataset(\"data/cube50k.dat\", \"STLs/Cube_38_1m.stl\", return_features_separately=False)\n",
    "dl = iter(DataLoader(ds, batch_size=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/Users/neelsortur/miniconda3/envs/satsims/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch as tr\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from e3nn import nn as enn\n",
    "from e3nn import o3\n",
    "from e3nn.nn import SO3Activation\n",
    "\n",
    "from rem import e3nn_utils\n",
    "from rem.equiv_gnn import GNN\n",
    "from rem.equiv_gnn_w_attrs import AttrGNN\n",
    "\n",
    "\n",
    "# TODO try getting rid of nonlinearities and see what happens\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "  def __init__(self, lmax_in, lmax_out, f_in, f_out, invariant_out=False):\n",
    "    super().__init__()\n",
    "    self.invariant_out = invariant_out\n",
    "\n",
    "    grid_s2 = e3nn_utils.s2_near_identity_grid()\n",
    "    grid_so3 = e3nn_utils.so3_near_identity_grid()\n",
    "\n",
    "    self.so3_conv1 = e3nn_utils.SO3Convolution(\n",
    "      f_in, 64, lmax_in, kernel_grid=grid_so3\n",
    "    )\n",
    "    self.act1 = SO3Activation(lmax_in, lmax_out, torch.relu, resolution=12)\n",
    "\n",
    "    self.so3_conv2 = e3nn_utils.SO3Convolution(\n",
    "      64, 128, lmax_in, kernel_grid=grid_so3\n",
    "    )\n",
    "    self.act2 = SO3Activation(lmax_in, lmax_out, torch.relu, resolution=12)\n",
    "\n",
    "    self.so3_conv3 = e3nn_utils.SO3Convolution(\n",
    "      128, 256, lmax_in, kernel_grid=grid_so3\n",
    "    )\n",
    "\n",
    "    # Output: Maps to 53 (rho_0, rho_1, rho_2, rho_3, ...) -> 53 S2 signals\n",
    "    if self.invariant_out:\n",
    "      self.act3 = SO3Activation(lmax_in, 0, torch.relu, resolution=12)\n",
    "      self.lin = o3.Linear(256, f_out)\n",
    "    else:\n",
    "      self.act3 = SO3Activation(lmax_in, lmax_out, torch.relu, resolution=12)\n",
    "      self.lin = e3nn_utils.SO3ToS2Convolution(\n",
    "        256, f_out, lmax_out, kernel_grid=grid_s2\n",
    "      )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.so3_conv1(x)\n",
    "    x = self.act1(x)\n",
    "\n",
    "    x = self.so3_conv2(x)\n",
    "    x = self.act2(x)\n",
    "\n",
    "    x = self.so3_conv3(x)\n",
    "    x = self.act3(x)\n",
    "\n",
    "    x = self.lin(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "class REM(nn.Module):\n",
    "  def __init__(self, num_node_features, z_lmax, max_radius, out_dim, invariant_out=False):\n",
    "    super().__init__()\n",
    "\n",
    "#    z_lmax = 4\n",
    "    self.lmax = z_lmax\n",
    "    self.out_dim = out_dim\n",
    "    self.invariant_out = invariant_out\n",
    "    f = 16\n",
    "\n",
    "    self.irreps_in = o3.Irreps(f\"{num_node_features}x0e\")\n",
    "    self.irreps_latent = e3nn_utils.so3_irreps(z_lmax)\n",
    "    self.irreps_enc_out = o3.Irreps(\n",
    "      #[(f, (l, p)) for l in range((z_lmax // 2) + 1) for p in [-1,1]]\n",
    "      [(f, (l, p)) for l in range((z_lmax) + 1) for p in [-1,1]]\n",
    "    )\n",
    "    if self.invariant_out:\n",
    "      self.irreps_node_attr = o3.Irreps(\"1x1e\")\n",
    "      self.encoder = AttrGNN(\n",
    "        irreps_node_input=self.irreps_in,\n",
    "        irreps_node_attr=self.irreps_node_attr,\n",
    "        irreps_node_output=self.irreps_enc_out,\n",
    "        max_radius=max_radius,\n",
    "        layers=2,\n",
    "        mul=f,\n",
    "        lmax=[self.lmax, self.lmax, self.lmax],\n",
    "      )\n",
    "    else:\n",
    "      self.encoder = GNN(\n",
    "        irreps_node_input=self.irreps_in,\n",
    "        irreps_node_output=self.irreps_enc_out,\n",
    "        max_radius=max_radius,\n",
    "        layers=2,\n",
    "        mul=f,\n",
    "        #lmax=[self.lmax // 2, self.lmax // 2, self.lmax // 2],\n",
    "        lmax=[self.lmax, self.lmax, self.lmax],\n",
    "      )\n",
    "\n",
    "    # TODO figure out what this linear layer actually is\n",
    "    # remove nonlinearities (could be an error) then VN could help\n",
    "    # equivariance error for encoder and decoder (on a layer by layer basis)\n",
    "    # overfit to a spherical signal in the decoder\n",
    "    # latent space\n",
    "    # TODO develop a baseline mesh to radar model and see what the error is\n",
    "    # resolution?\n",
    "    self.lin = o3.Linear(self.irreps_enc_out, self.irreps_latent, f_in=1, f_out=f)\n",
    "    self.decoder = Decoder(z_lmax, z_lmax, f, out_dim, invariant_out=invariant_out)\n",
    "\n",
    "  def forward(self, x, return_latent=False):\n",
    "    batch_size = x.batch.max() + 1\n",
    "    gnn_out = self.encoder(x)\n",
    "    z = self.lin(gnn_out.view(batch_size, 1, -1))\n",
    "    out = self.decoder(z)\n",
    "    cartesian = self.ar2los(x.orientation)\n",
    "    out_response = self._getResponse(out, cartesian)\n",
    "\n",
    "    if return_latent:\n",
    "      return (out_response, out)\n",
    "    else:\n",
    "      return out_response\n",
    "\n",
    "  def _getResponse(self, out, pose):\n",
    "    if self.invariant_out:\n",
    "      return out\n",
    "    else:\n",
    "      sh = torch.concatenate(\n",
    "        [o3.spherical_harmonics(l, pose, True) for l in range(self.lmax + 1)], dim=1\n",
    "      ).unsqueeze(2)  # B x (L^2 * S^2) x 1\n",
    "      response = torch.bmm(out, sh).squeeze()  # B x D\n",
    "\n",
    "      return response\n",
    "    \n",
    "  def ar2los(self, x_ar):\n",
    "    \"\"\"Convert a unit spherical coordinate to cartesian.\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_ar: Tensor, shape-(N, ..., [2, 4, 6])\n",
    "        Aspect/Roll coordinates\n",
    "    Returns\n",
    "    -------\n",
    "    x_los: Tensor, shape-(N, ..., [3, 6, 9])\n",
    "        Cartesian coordinates\n",
    "    \"\"\"\n",
    "    assert x_ar.shape[-1] % 2 == 0\n",
    "    assert x_ar.shape[-1] <= 6\n",
    "\n",
    "    # Line-of-sight in XYZ\n",
    "    a = x_ar[..., 0]\n",
    "    r = x_ar[..., 1]\n",
    "\n",
    "    x = -tr.sin(a) * tr.cos(r)\n",
    "    y = -tr.sin(a) * tr.sin(r)\n",
    "    z = -tr.cos(a)\n",
    "\n",
    "    if x_ar.shape[-1] == 2:\n",
    "        return tr.stack([x, y, z], dim=-1)\n",
    "\n",
    "    # First time derivative\n",
    "    da_dt = x_ar[..., 2]\n",
    "    dr_dt = x_ar[..., 3]\n",
    "\n",
    "    # Non-zero partial derivatives\n",
    "    dxlos_da = -tr.cos(a) * tr.cos(r)\n",
    "    dxlos_dr = tr.sin(a) * tr.sin(r)\n",
    "    dylos_da = -tr.cos(a) * tr.sin(r)\n",
    "    dylos_dr = -tr.sin(a) * tr.cos(r)\n",
    "    dzlos_da = tr.sin(a)\n",
    "\n",
    "    # Time derivative of line-of-sight\n",
    "    xd = dxlos_da * da_dt + dxlos_dr * dr_dt\n",
    "    yd = dylos_da * da_dt + dylos_dr * dr_dt\n",
    "    zd = dzlos_da * da_dt\n",
    "\n",
    "    if x_ar.shape[-1] == 4:\n",
    "        return tr.stack([x, y, z, xd, yd, zd], dim=-1)\n",
    "\n",
    "    da_dtdt = x_ar[..., 4]\n",
    "    dr_dtdt = x_ar[..., 5]\n",
    "\n",
    "    # Second partial derivatives\n",
    "    dxlos_dada = tr.sin(a) * tr.cos(r)\n",
    "    dxlos_dadr = tr.cos(a) * tr.sin(r)\n",
    "    dxlos_drda = tr.cos(a) * tr.sin(r)\n",
    "    dxlos_drdr = tr.sin(a) * tr.cos(r)\n",
    "    dylos_dada = tr.sin(a) * tr.sin(r)\n",
    "    dylos_dadr = -tr.cos(a) * tr.cos(r)\n",
    "    dylos_drda = -tr.cos(a) * tr.cos(r)\n",
    "    dylos_drdr = tr.sin(a) * tr.sin(r)\n",
    "    dzlos_dada = tr.cos(a)\n",
    "\n",
    "    # Second time derivative of line-of-sight\n",
    "    xdd = (\n",
    "        (dxlos_dada * da_dt + dxlos_dadr * dr_dt) * da_dt\n",
    "        + dxlos_da * da_dtdt\n",
    "        + (dxlos_drda * da_dt + dxlos_drdr * dr_dt) * dr_dt\n",
    "        + dxlos_dr * dr_dtdt\n",
    "    )\n",
    "    ydd = (\n",
    "        (dylos_dada * da_dt + dylos_dadr * dr_dt) * da_dt\n",
    "        + dylos_da * da_dtdt\n",
    "        + (dylos_drda * da_dt + dylos_drdr * dr_dt) * dr_dt\n",
    "        + dylos_dr * dr_dtdt\n",
    "    )\n",
    "    zdd = (dzlos_dada * da_dt) * da_dt + dzlos_da * da_dtdt\n",
    "\n",
    "    return tr.stack([x, y, z, xd, yd, zd, xdd, ydd, zdd], dim=-1)\n",
    "\n",
    "rem = REM(num_node_features=5, z_lmax=4, max_radius=1.8, out_dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test equivariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0114, grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "samp, y = next(dl)\n",
    "samp_copy = samp.clone()\n",
    "print(rem(samp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7320507764816284\n"
     ]
    }
   ],
   "source": [
    "def compute_max_radius(data) -> float:\n",
    "    \"\"\"\n",
    "    Computes the maximum radius (maximum pairwise Euclidean distance) \n",
    "    for a torch_geometric Data object.\n",
    "\n",
    "    Parameters:\n",
    "        data (Data): A PyTorch Geometric Data object with node positions in `data.pos`.\n",
    "\n",
    "    Returns:\n",
    "        float: The maximum radius.\n",
    "    \"\"\"\n",
    "    # Ensure the data object has 'pos' attribute\n",
    "    if not hasattr(data, 'pos') or data.pos is None:\n",
    "        raise ValueError(\"The Data object must have a 'pos' attribute for node positions.\")\n",
    "\n",
    "    # Compute pairwise distances\n",
    "    pairwise_distances = torch.cdist(data.pos, data.pos, p=2)\n",
    "\n",
    "    # Get the maximum distance\n",
    "    max_radius = pairwise_distances.max().item()\n",
    "    \n",
    "    return max_radius\n",
    "\n",
    "print(compute_max_radius(samp_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from e3nn.o3 import rand_matrix\n",
    "samp, y = next(dl)\n",
    "samp_copy = samp.clone()\n",
    "\n",
    "def spherical_to_cartesian(alpha, beta):\n",
    "    \"\"\"\n",
    "    Convert spherical angles (alpha, beta) to cartesian coordinates.\n",
    "    alpha: azimuthal angle, beta: polar angle\n",
    "    \"\"\"\n",
    "    x = torch.cos(beta) * torch.cos(alpha)\n",
    "    y = torch.cos(beta) * torch.sin(alpha)\n",
    "    z = torch.sin(beta)\n",
    "    return torch.stack([x, y, z], dim=-1)\n",
    "\n",
    "\n",
    "def rotate_orientation(orientation, R):\n",
    "    \"\"\"\n",
    "    Rotate 2D orientation (alpha, beta) values using a rotation matrix.\n",
    "    Orientation is converted to Cartesian, rotated, and then converted back.\n",
    "    \"\"\"\n",
    "    # Convert spherical angles (alpha, beta) to Cartesian coordinates\n",
    "    cartesian = spherical_to_cartesian(orientation[:, 0], orientation[:, 1])\n",
    "\n",
    "    # Apply rotation\n",
    "    rotated_cartesian = torch.einsum('ij,nj->ni', R, cartesian)\n",
    "\n",
    "    # Convert back to spherical coordinates\n",
    "    rho = rotated_cartesian.norm(dim=-1)\n",
    "    beta = torch.asin(rotated_cartesian[:, 2] / rho)\n",
    "    alpha = torch.atan2(rotated_cartesian[:, 1], rotated_cartesian[:, 0])\n",
    "    return torch.stack([alpha, beta], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original orientation tensor([[2.4197, 0.7810]])\n",
      "New orientation tensor([[-2.2189,  0.4885]])\n",
      "New orientation random tensor([[-1.8800,  0.1439]])\n",
      "Output original tensor(0.0013)\n",
      "Output rotated tensor(0.0010)\n",
      "Output rotated random tensor(0.0005)\n",
      "Equivariance Test: Failed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def test_encoder_equivariance(rem, data):\n",
    "    \"\"\"\n",
    "    Test the equivariance of rem.encoder with respect to SO(3) rotations.\n",
    "\n",
    "    Parameters:\n",
    "        rem: REM\n",
    "            The REM model with the encoder to test.\n",
    "        data: torch_geometric.data.Data\n",
    "            Input graph data with `data.orientation` as (alpha, beta).\n",
    "\n",
    "    Returns:\n",
    "        bool: True if invariant, False otherwise.\n",
    "    \"\"\"\n",
    "    # Generate a random SO(3) rotation matrix\n",
    "    # R = rand_matrix()\n",
    "    R = torch.tensor([\n",
    "        [1, 0, 0],\n",
    "        [0, 0, -1],\n",
    "        [0, 1, 0]\n",
    "    ], dtype=torch.float32)\n",
    "\n",
    "    # Rotate orientation\n",
    "    original_orientation = data.orientation.clone()\n",
    "    print(\"Original orientation\", original_orientation)\n",
    "    rotated_orientation = rotate_orientation(original_orientation, R)\n",
    "    print(\"New orientation\", rotated_orientation)\n",
    "\n",
    "    R_random = o3.rand_matrix()\n",
    "    rotated_orientation_random = rotate_orientation(original_orientation, R_random)\n",
    "    print(\"New orientation random\", rotated_orientation_random)\n",
    "\n",
    "    # Clone data and apply rotated orientation\n",
    "    data_rotated = data.clone()\n",
    "    data_rotated.orientation = rotated_orientation\n",
    "\n",
    "    data_rotated_random = data.clone()\n",
    "    data_rotated_random.orientation = rotated_orientation_random\n",
    "\n",
    "    # Forward pass on original and rotated data\n",
    "    rem.eval()  # Ensure evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output_original = rem(data)\n",
    "        print(\"Output original\", output_original)\n",
    "        output_rotated = rem(data_rotated)\n",
    "        print(\"Output rotated\", output_rotated)\n",
    "        output_rotated_random = rem(data_rotated_random)\n",
    "        print(\"Output rotated random\", output_rotated_random)\n",
    "\n",
    "    # Check invariance: the outputs should be identical\n",
    "    is_invariant = torch.allclose(output_original, output_rotated, atol=1e-6)\n",
    "\n",
    "    print(f\"Equivariance Test: {'Passed' if is_invariant else 'Failed'}\")\n",
    "    return is_invariant\n",
    "\n",
    "test_encoder_equivariance(rem, samp_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO try what chatgpt says\n",
    "\n",
    "Try all close on each layer's latent tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satsims",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
